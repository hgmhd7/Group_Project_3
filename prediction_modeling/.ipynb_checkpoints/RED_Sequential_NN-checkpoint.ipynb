{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import initial dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSVs to DFs\n",
    "features = \"output/reduced_wine_features.csv\"\n",
    "targets = \"output/reduced_wine_targets.csv\"\n",
    "\n",
    "features_df = pd.read_csv(features)\n",
    "targets_df =pd.read_csv(targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>country_Portugal</th>\n",
       "      <th>country_US</th>\n",
       "      <th>red_flavor_categories_light and fuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  country_Portugal  country_US  red_flavor_categories_light and fuity\n",
       "0   15.0                 1           0                                      1\n",
       "1   65.0                 0           1                                      0\n",
       "2   19.0                 0           1                                      1\n",
       "3   34.0                 0           1                                      0\n",
       "4   30.0                 0           0                                      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF head\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68776, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature DF shape\n",
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   points\n",
       "0      87\n",
       "1      87\n",
       "2      87\n",
       "3      87\n",
       "4      87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68776, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check target DF shape\n",
    "targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.  1.  0.  1.]\n",
      " [65.  0.  1.  0.]\n",
      " [19.  0.  1.  1.]\n",
      " ...\n",
      " [40.  0.  0.  0.]\n",
      " [20.  0.  0.  0.]\n",
      " [75.  0.  1.  0.]] [[87]\n",
      " [87]\n",
      " [87]\n",
      " ...\n",
      " [90]\n",
      " [90]\n",
      " [90]]\n"
     ]
    }
   ],
   "source": [
    "# Assign the features and target to X and y abd check assignments\n",
    "raw_feature_data = features_df.values\n",
    "raw_target_data = targets_df.values\n",
    "X = raw_feature_data[:, 0:5]\n",
    "y = raw_target_data.reshape(-1,1)\n",
    "\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT, NORMALIZE, AND ENCODE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test sets for the features and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using the MinMax scaler since we know their values\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler().fit(y_train)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPERAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the sequential and dense modules fo build my NN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Model...\n",
      "parameters:\n",
      "{'batch_size': [10, 20, 40, 60, 80, 100],\n",
      " 'learning_rate': [0.01, 0.001, 0.0001],\n",
      " 'max_depth': [3, 5, 7, 9],\n",
      " 'n_estimators': [200, 300, 500]}\n",
      "[10:31:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score: 0.394\n",
      "Best parameters set:\n",
      "\tbatch_size: 10\n",
      "\tlearning_rate: 0.01\n",
      "\tmax_depth: 5\n",
      "\tn_estimators: 500\n",
      "Select Done..., Time Cost: 3418.\n"
     ]
    }
   ],
   "source": [
    "print('Select Model...')\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "start_time  = datetime.now()\n",
    "xgb_clf = XGBRegressor() \n",
    "parameters = {'n_estimators': [200, 300, 500], 'max_depth':[3,5,7,9], \\\n",
    "              'learning_rate':[.01, .001, .0001], 'batch_size':[10, 20, 40, 60, 80, 100]}\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=10, n_jobs=-1)\n",
    "print(\"parameters:\")\n",
    "pprint.pprint(parameters)\n",
    "grid_search.fit(X_train_scaled, y_train_scaled.ravel())\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters=grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "end_time = datetime.now()\n",
    "print(f'Select Done..., Time Cost: {((end_time - start_time).seconds)}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.014704609038281724\n",
      "R-squared (R2): 0.3956518367935681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted_5 = grid_search.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_5 = mean_squared_error(y_test_scaled, predicted_5)\n",
    "r2_5 = r2_score(y_test_scaled, predicted_5)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_5}\")\n",
    "print(f\"R-squared (R2): {r2_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5287669 , 0.5398442 , 0.29520985, ..., 0.48204508, 0.42631766,\n",
       "       0.48962787], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_list = grid_search.predict(X_test_scaled)\n",
    "\n",
    "predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5287669 , 0.5398442 , 0.29520985, ..., 0.48204508, 0.42631766,\n",
       "       0.48962787], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_list = y_test_scaled\n",
    "\n",
    "predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Predictions</th>\n",
       "      <th>Actual_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.528767</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539844</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494980</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.529106</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.288520</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.402724</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.365748</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.560576</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.493237</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.515782</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.447810</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.357096</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.365748</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.251289</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.446257</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.417879</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.545558</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGB_Predictions  Actual_Points\n",
       "0          0.528767           0.60\n",
       "1          0.539844           0.50\n",
       "2          0.295210           0.30\n",
       "3          0.494980           0.55\n",
       "4          0.529106           0.45\n",
       "5          0.288520           0.25\n",
       "6          0.402724           0.50\n",
       "7          0.365748           0.25\n",
       "8          0.560576           0.75\n",
       "9          0.493237           0.60\n",
       "10         0.515782           0.60\n",
       "11         0.447810           0.35\n",
       "12         0.357096           0.10\n",
       "13         0.560672           0.65\n",
       "14         0.365748           0.35\n",
       "15         0.251289           0.35\n",
       "16         0.446257           0.55\n",
       "17         0.560672           0.65\n",
       "18         0.417879           0.55\n",
       "19         0.545558           0.65"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_comparrisons_df = pd.DataFrame({'XGB_Predictions':predicted_list,\n",
    "                                           'Actual_Points':actual_list.ravel()\n",
    "                                          })\n",
    "\n",
    "prediction_comparrisons_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_comparrisons_df.to_csv(r'C:\\Users\\howar\\Desktop\\Data Science Boot Camp\\Group_Project_3\\Group_Project_3\\prediction_modeling\\output\\predictions_vs_acttual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Model...\n",
      "parameters:\n",
      "{'batch_size': [10],\n",
      " 'learning_rate': [0.01],\n",
      " 'max_depth': [5],\n",
      " 'n_estimators': [200, 300, 500]}\n",
      "[10:59:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score: 0.359\n",
      "Best parameters set:\n",
      "\tbatch_size: 10\n",
      "\tlearning_rate: 0.01\n",
      "\tmax_depth: 5\n",
      "\tn_estimators: 500\n",
      "Select Done..., Time Cost: 37.\n"
     ]
    }
   ],
   "source": [
    "print('Select Model...')\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "start_time  = datetime.now()\n",
    "xgb_clf = XGBRegressor() \n",
    "parameters = {'n_estimators': [200, 300, 500], 'max_depth':[5], \\\n",
    "              'learning_rate':[.01], 'batch_size':[10]}\n",
    "grid_search_2 = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=10, n_jobs=-1)\n",
    "print(\"parameters:\")\n",
    "pprint.pprint(parameters)\n",
    "grid_2 = grid_search_2.fit(X_train, y_train.ravel())\n",
    "print(\"Best score: %0.3f\" % grid_2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters=grid_2.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "end_time = datetime.now()\n",
    "print(f'Select Done..., Time Cost: {((end_time - start_time).seconds)}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 6.193746039224186\n",
      "R-squared (R2): 0.3636044602703611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted_6 = grid_2.predict(X_test)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_6 = mean_squared_error(y_test, predicted_6)\n",
    "r2_6 = r2_score(y_test, predicted_6)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_6}\")\n",
    "print(f\"R-squared (R2): {r2_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89.94345 , 90.18756 , 85.36217 , ..., 89.063385, 87.92288 ,\n",
       "       89.26439 ], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_list_unscaled = grid_2.predict(X_test)\n",
    "\n",
    "predicted_list_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92],\n",
       "       [90],\n",
       "       [86],\n",
       "       ...,\n",
       "       [93],\n",
       "       [87],\n",
       "       [91]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_list_unscaled = y_test\n",
    "\n",
    "actual_list_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Predictions (unscaled)</th>\n",
       "      <th>Actual_Points (unscaled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.943451</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.187561</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.362167</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.137169</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.054260</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85.278992</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.471840</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86.731483</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90.595421</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>89.256577</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89.684715</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88.421356</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86.555740</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90.601334</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>86.731483</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84.412659</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>88.300667</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90.601334</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>87.764160</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90.166588</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGB_Predictions (unscaled)  Actual_Points (unscaled)\n",
       "0                    89.943451                        92\n",
       "1                    90.187561                        90\n",
       "2                    85.362167                        86\n",
       "3                    89.137169                        91\n",
       "4                    90.054260                        89\n",
       "5                    85.278992                        85\n",
       "6                    87.471840                        90\n",
       "7                    86.731483                        85\n",
       "8                    90.595421                        95\n",
       "9                    89.256577                        92\n",
       "10                   89.684715                        92\n",
       "11                   88.421356                        87\n",
       "12                   86.555740                        82\n",
       "13                   90.601334                        93\n",
       "14                   86.731483                        87\n",
       "15                   84.412659                        87\n",
       "16                   88.300667                        91\n",
       "17                   90.601334                        93\n",
       "18                   87.764160                        91\n",
       "19                   90.166588                        93"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_comparrisons_unscaled_df = pd.DataFrame({'XGB_Predictions (unscaled)' : predicted_list_unscaled,\n",
    "                                           'Actual_Points (unscaled)' : actual_list_unscaled.ravel()\n",
    "                                          })\n",
    "\n",
    "prediction_comparrisons_unscaled_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_comparrisons_unscaled_df.to_csv(r'C:\\Users\\howar\\Desktop\\Data Science Boot Camp\\Group_Project_3\\Group_Project_3\\prediction_modeling\\output\\predictions_vs_actual_unscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 26 candidates, totalling 52 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [25, 10, 4, 2, 1.0, 0.8, 0.5, 0.3, 0.2, 0.1,\n",
       "                                   0.05, 0.02, 0.01],\n",
       "                         'normalize': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "       'normalize': [True, False]}\n",
    "rdg_reg = Ridge()\n",
    "clf = GridSearchCV(rdg_reg,params,cv=2,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train_scaled, y_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.019730 using {'alpha': 0.01, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "# Print the score and best params for the activation model\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.019410384900731423\n",
      "R-squared (R2): 0.2022480549229445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to predict a value\n",
    "predicted_2 = clf.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_2 = mean_squared_error(y_test_scaled, predicted_2)\n",
    "r2_2 = r2_score(y_test_scaled, predicted_2)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_2}\")\n",
    "print(f\"R-squared (R2): {r2_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def cross_validate_best_known():\n",
    "    '''\n",
    "        import and clean the tractor data, then do a corss validation on each of the three models we are\n",
    "        training here. A RandomForest, a GradientBoost, and an AdaBoost backed by a DecisionTree. Print\n",
    "        the scores.\n",
    "\n",
    "        The parameters we're using here are the \"best\" that we've found so far using a grid search.\n",
    "    '''\n",
    "\n",
    "rf = RandomForestRegressor(max_features=2, min_samples_split=4, n_estimators=50, min_samples_leaf=2)\n",
    "gb = GradientBoostingRegressor(loss='quantile', learning_rate=0.0001, n_estimators=50, max_features='log2', min_samples_split=2, max_depth=1)\n",
    "ada_tree_backing = DecisionTreeRegressor(max_features='sqrt', splitter='random', min_samples_split=4, max_depth=3)\n",
    "ab = AdaBoostRegressor(ada_tree_backing, learning_rate=0.0001, loss='square', n_estimators=100000)\n",
    "\n",
    "\n",
    "rf.fit(X_train_scaled, y_train_scaled.ravel())\n",
    "# validate.cross_v_scores([rf, gb, ab], X_train_scaled, y_train_scaled)\n",
    "# # RandomForestRegressor -- RMLSE: -0.596797712098, R2: 0.0272065373946\n",
    "# GradientBoostingRegressor -- RMLSE: -0.996134592541, R2: -2.37202164829\n",
    "# AdaBoostRegressor -- RMLSE: -0.706385708459, R2: -0.103966980393 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_tree_backing.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.fit(X_train_scaled, y_train_scaled.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model to predict a value\n",
    "predicted_3 = ab.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse_3 = mean_squared_error(y_test_scaled, predicted_3)\n",
    "r2_3 = r2_score(y_test_scaled, predicted_3)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_3}\")\n",
    "print(f\"R-squared (R2): {r2_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE BELOW CONTAINS DIFFERENT GRID SEARCHS I WAS TESTING OUT\n",
    "# KEEPING THIS IN THE NOTEBOOK FOR FUTURE REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for activation method\n",
    "# def create_base_model(activation='relu'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create activation model\n",
    "# model = KerasClassifier(build_fn=create_base_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "\n",
    "# # Assign the activation grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = activation_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the activation model\n",
    "# print(\"Best: %f using %s\" % (activation_grid_result.best_score_, activation_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {activation_grid_result.score(X_train_scaled, y_train_categorical)}\")\n",
    "# print(f\"Testing Data Score: {activation_grid_result.score(X_test_scaled, y_test_categorical)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for the model\n",
    "# def create_model(activation='adam', dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create model\n",
    "# model = KerasClassifier(build_fn=create_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the activation and dropout rate grid search parameters\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the grid search parameters, fit, and run the model\n",
    "# param_grid = dict(activation=activation, dropout_rate=dropout_rate)\n",
    "# fit_grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = fit_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the activation model\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for optimizer model\n",
    "# def create_optimizer_model(optimizer='adam'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=100, activation='hard_sigmoid'))\n",
    "#     model.add(Dense(units=3, activation='hard_sigmoid'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create optimizer model\n",
    "# optimizer_model = KerasClassifier(build_fn=create_optimizer_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the optimizer grid search parameters\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# # Assign the optimizer grid search parameters, fit, and run the model\n",
    "# optimizer_param_grid = dict(optimizer=optimizer)\n",
    "# optimizer_grid = GridSearchCV(estimator=optimizer_model, param_grid=optimizer_param_grid, n_jobs=-1)\n",
    "# optimizer_grid_result = optimizer_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the optimizer model\n",
    "# print(\"Best: %f using %s\" % (optimizer_grid_result.best_score_, optimizer_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the base Keras classifier wrapper for dropout model\n",
    "# def create_dropout_model(dropout_rate=0.0):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=100, activation='tanh'))\n",
    "#     model.add(Dense(units=100, activation='relu'))\n",
    "#     model.add(Dense(units=3, activation='softmax'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy']) \n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # Create the dropout model\n",
    "# dropout_model = KerasClassifier(build_fn=create_dropout_model, epochs=250, batch_size=88)\n",
    "\n",
    "\n",
    "# # Define the dropout grid search parameters\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# # Assign the dropout grid search parameters, fit, and run the model\n",
    "# dropout_param_grid = dict(dropout_rate=dropout_rate)\n",
    "# dropout_grid = GridSearchCV(estimator=dropout_model, param_grid=dropout_param_grid, n_jobs=-1)\n",
    "# dropout_grid_result = dropout_grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the score and best params for the dropout model\n",
    "# print(\"Best: %f using %s\" % (dropout_grid_result.best_score_, dropout_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
